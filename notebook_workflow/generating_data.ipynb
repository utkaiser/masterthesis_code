{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Generating data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This notebook explains how to generate data that can be used for training and evaluation the end-to-end model of the master's thesis “Wave propagation aided by Deep Learning” by Luis Kaiser, supervised by Prof. Tsai (University of Texas Austin) and Prof. Klingenberg (University of Wuerzburg), in practice. More information about the algorithm can be found in my [code](https://github.com/utkaiser/masterthesis_code) or [writeup](https://github.com/utkaiser/masterthesis_writing). Parts of this code are extracted from the files `generate_data/generate_velocity_crop.py` and `generate_data/datagen_end_to_end.py`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, make sure that you have install all necessary libraries specified in `requirements.txt` using `pip` or `pip3` depending on your setup by running the command below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip3 install --upgrade pip\n",
    "!pip3 install -r requirements.txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We first generate the random velocity profile crops from `../data/velocity_profiles/marm1nonsmooth.mat` and `../data/velocity_profiles/bp2004.mat` and save the results in an `.npz` file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from generate_data.generate_velocity_crop import generate_velocity_profile_crop\n",
    "from skimage.filters import gaussian\n",
    "from scipy.io import loadmat\n",
    "\n",
    "\n",
    "def generate_velocity_crops(\n",
    "        resolution = 256,\n",
    "        output_dir = 'crop_test.npz',\n",
    "        num_crops = 1,\n",
    "):\n",
    "    '''\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    resolution : (int) resolution of crop\n",
    "    output_dir : (string) output file path, ending with \".npz\"\n",
    "    num_crops :  (int) number of crops per image\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    saves the velocity crops in an .npz-file\n",
    "    '''\n",
    "\n",
    "    # load images\n",
    "    datamat = loadmat('../data/velocity_profiles/marm1nonsmooth.mat')  # Marmousi velocity image\n",
    "    fullmarm = gaussian(datamat['marm1larg'],4)  # smoothing the image\n",
    "    databp = loadmat('../data/velocity_profiles/bp2004.mat')  # BP velocity image\n",
    "    fullbp = gaussian(databp['V'],4)/1000  # smoothing the image and different order of magnitude\n",
    "\n",
    "    # randomly crop and save images at \"output_dir\"\n",
    "    generate_velocity_profile_crop(\n",
    "        v_images = [fullmarm,fullbp],\n",
    "        m = resolution,\n",
    "        output_path = output_dir,\n",
    "        num_times = num_crops\n",
    "    )\n",
    "\n",
    "\n",
    "generate_velocity_crops()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then use numerical solvers shown in `use_numerical_solvers.ipynb` to advance a wave field on these velocity profiles. The data is stored in a `.npz` file and can later be used for training and evaluation the models. Note that the design of the function `generate_wave_from_medium` is not optimal for this purpose since it was used and changed for different applications. However, this should provide you with the basic workflow on how to generate data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from generate_data.initial_conditions import initial_condition_gaussian\n",
    "import torch\n",
    "from generate_data.utils import crop_center\n",
    "from generate_data.change_wave_arguments import  WaveSol_from_EnergyComponent_tensor, WaveEnergyComponentField_end_to_end,WaveEnergyField\n",
    "from generate_data.utils_wave_propagate import one_iteration_pseudo_spectral_tensor, one_iteration_velocity_verlet\n",
    "\n",
    "\n",
    "def visualize_wavefield(\n",
    "        u_elapse,\n",
    "        ut_elapse,\n",
    "        vel,\n",
    "        f_delta_x,\n",
    "        it,\n",
    "        s\n",
    "):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    u_elapse : (numpy tensor) wave field component u\n",
    "    ut_elapse : (numpy tensor) wave field component u derived by t, i.e. the velocity\n",
    "    vel : (numpy tensor) velocity profile image\n",
    "    f_delta_x : (float) grid time stepping of solver\n",
    "    it : (int) number of current iteration\n",
    "    s : (int) number of current snapshot\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    visualizes current wave field iteration\n",
    "    '''\n",
    "\n",
    "    # change representation to energy semi-norm\n",
    "    w = WaveEnergyField(u_elapse.squeeze().numpy(),ut_elapse.squeeze().numpy(),vel, f_delta_x)\n",
    "\n",
    "    # visualize results\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(w)\n",
    "    plt.title(f\"wave field for iteration {it} and snapshot {s}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def generate_data_end_to_end(\n",
    "        input_path = \"crop_test.npz\",\n",
    "        output_path = \"datagen_test.npz\",\n",
    "        boundary_condition = \"periodic\",\n",
    "        n_snaps = 10,\n",
    "        res = 256,\n",
    "        n_it = 2,\n",
    "        f_delta_x =  2. / 256.\n",
    "):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_path : (string) velocity profile data path\n",
    "    output_path: (string) wave field data path\n",
    "    boundary_condition : (string) boundary condition, either \"periodic\" or \"absorbing\"\n",
    "    n_snaps : (int) amount of snapshots / dt_star steps to take\n",
    "    res : (int) resolution of wave field output\n",
    "    n_it : (int) amount of different wave propagation series\n",
    "    f_delta_x : (float) grid time stepping of solver\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    saves generated wave propagation iterations in file\n",
    "    '''\n",
    "\n",
    "    # load velocity model created in function above `generate_velocity_crops()`\n",
    "    velocities = np.load(input_path)['wavespeedlist']\n",
    "\n",
    "    # setup tensors to store wave energy components and velocity profile\n",
    "    # save image for each iteration and snapshot\n",
    "    Ux, Uy, Utc = np.zeros([n_it, n_snaps + 1, res, res]), \\\n",
    "                  np.zeros([n_it, n_snaps + 1, res, res]), \\\n",
    "                  np.zeros([n_it, n_snaps + 1, res, res])\n",
    "    V = np.zeros([n_it, n_snaps+1, res, res])\n",
    "\n",
    "    # training\n",
    "    for it in range(n_it):\n",
    "\n",
    "        # sample velocity instance\n",
    "        vel = velocities[it]  # w_big x h_big\n",
    "\n",
    "        # computing initial condition using gaussian pulse (switch to pytorch tensor if needed)\n",
    "        # note that this will contain the energy components,\n",
    "        # i.e. u_energy[b][0,...,2] relates to the partial derivatives mentioned in the thesis, while b denotes the batch\n",
    "        u_energy = initial_condition_gaussian(\n",
    "            torch.from_numpy(vel),\n",
    "            resolution=res,\n",
    "            boundary_condition=\"periodic\",\n",
    "            mode=\"other\",\n",
    "            res_padded=res,\n",
    "            optimization = \"none\",\n",
    "        )\n",
    "\n",
    "        # create and save velocity crop\n",
    "        vel_crop = crop_center(vel, res, boundary_condition, 2)  # crop center of the image if boundary condition == \"absorbing\"\n",
    "        V[it] = np.repeat(vel[np.newaxis, :, :], n_snaps + 1, axis=0)  # save velocity image (n_snaps + 1) times in V\n",
    "\n",
    "        # visualize velocity profile used for iterations\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(vel_crop)\n",
    "        plt.show()\n",
    "        plt.title(f\"velocity profile for iteration {it}\")\n",
    "\n",
    "        # integrate dt_star (step size) n_snaps times\n",
    "        for s in range(n_snaps+1):\n",
    "\n",
    "            # change energy components to wave field representation\n",
    "            u_elapse, ut_elapse = WaveSol_from_EnergyComponent_tensor(\n",
    "                u_energy[:,0],\n",
    "                u_energy[:,1],\n",
    "                u_energy[:,2],\n",
    "                torch.from_numpy(vel),\n",
    "                f_delta_x,\n",
    "                torch.sum(torch.sum(torch.sum(u_energy[:,0])))\n",
    "            )\n",
    "\n",
    "            visualize_wavefield(\n",
    "                u_elapse,\n",
    "                ut_elapse,\n",
    "                vel,\n",
    "                f_delta_x,\n",
    "                it,\n",
    "                s\n",
    "            )\n",
    "\n",
    "            if boundary_condition == \"absorbing\":\n",
    "\n",
    "                # cropping and save current snapshot in tensors\n",
    "                u_elapse_crop, ut_elapse_crop = crop_center(u_elapse.squeeze(), res, boundary_condition, 2),crop_center(ut_elapse.squeeze(), res, boundary_condition, 2)\n",
    "                Ux[it, s], Uy[it, s], Utc[it, s] = \\\n",
    "                    WaveEnergyComponentField_end_to_end(u_elapse_crop, ut_elapse_crop, vel_crop, f_delta_x)\n",
    "\n",
    "            else:\n",
    "                # save current snapshot in tensors\n",
    "                Ux[it, s], Uy[it, s], Utc[it, s] = u_energy[0,0], u_energy[0,1], u_energy[0,2]\n",
    "\n",
    "            # itegration step (done for all iterations only not for last one)\n",
    "            if s < n_snaps + 1:\n",
    "                # apply pseudo spectral solver (alternatively the velocity verlet solver)\n",
    "                u_energy = one_iteration_pseudo_spectral_tensor(\n",
    "                    torch.cat([u_energy, torch.from_numpy(vel).unsqueeze(dim=0).unsqueeze(dim=0)], dim=1))\n",
    "\n",
    "    # save tensors in file, accessible through key-value queries\n",
    "    np.savez(output_path, vel=V, Ux=Ux, Uy=Uy, Utc=Utc)\n",
    "\n",
    "\n",
    "generate_data_end_to_end()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
