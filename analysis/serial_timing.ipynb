{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import generate_data.WaveUtil as WaveUtil\n",
    "import generate_data.wave2 as wave2\n",
    "import generate_data.WavePostprocess as wp\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "params = {'legend.fontsize': 'xx-large',\n",
    "          'figure.figsize': (8, 6),\n",
    "         'axes.labelsize': 'xx-large',\n",
    "         'axes.titlesize':'xx-large',\n",
    "         'xtick.labelsize':'xx-large',\n",
    "         'ytick.labelsize':'xx-large'}\n",
    "plt.rcParams.update(params)\n",
    "plt.rcParams['font.size'] = '14'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unet 3lvl number of trainable parameters 2561208\n",
      "tiramisu 55-55 number of trainable parameters 691283\n"
     ]
    }
   ],
   "source": [
    "# set up models\n",
    "import torch\n",
    "import models.tiramisu as tiramisu\n",
    "import models.unet as unet\n",
    "import old_code.unet_Linear as unet2\n",
    "\n",
    "#unet model setup\n",
    "#unet_model = unet.UNet(wf=1, depth=3, scale_factor=2)\n",
    "unet_model = unet2.UNet(depth=6, wf=1, acti_func='relu', scale_factor=4)\n",
    "#unet_model = torch.nn.DataParallel(unet_model)\n",
    "unet_model.load_state_dict(torch.load('../results/run_1/saved_model_unet256_10.pt'))\n",
    "unet_model.eval()\n",
    "unet_model = unet_model.double()\n",
    "\n",
    "#tiramisu model setup\n",
    "tir_model = tiramisu.FCDenseNet(scale_factor=4)\n",
    "tir_model = torch.nn.DataParallel(tir_model)\n",
    "#tir_model = unet2.UNet(depth=6, wf=1, acti_func='relu')\n",
    "tir_model.load_state_dict(torch.load('../results/run_1/saved_model_tiramisu256_1.pt'))\n",
    "tir_model.eval()\n",
    "tir_model = tir_model.double()\n",
    "\n",
    "netlist = [\n",
    "    (r'unet 3lvl', unet_model),\n",
    "    (r'tiramisu 55-55', tir_model)\n",
    "]\n",
    "\n",
    "for netname,netmodl in netlist:\n",
    "    model_parameters = filter(lambda p: p.requires_grad, netmodl.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(netname,'number of trainable parameters', params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter setup\n",
    "\n",
    "Tf = 2.0\n",
    "cT = 0.2\n",
    "dx = 1.0/128.0 #2.0/128.0\n",
    "dt = dx / 20\n",
    "ny, nx = 64, 64\n",
    "m = 4 #2\n",
    "rt = 4\n",
    "mt = round(Tf/cT)\n",
    "t = np.linspace(0,Tf,mt)\n",
    "x = np.arange(-1,1,dx)\n",
    "y = np.arange(-1,1,dx)\n",
    "xx,yy = np.meshgrid(x,y)\n",
    "\n",
    "np.random.seed = 21\n",
    "center = np.array([0.,0.])\n",
    "# center_1 = np.array([-0.8,-0.8])\n",
    "# u0_1 = np.exp(-250.0*(0.2*(xx-center_1[0])**2 + (yy-center_1[1])**2))*np.cos(8*np.pi*(yy-center_1[1]))\n",
    "# center_2 = np.array([.8,.8])\n",
    "# u0_2 = np.exp(-250.0*(0.2*(xx-center_2[0])**2 + (yy-center_2[1])**2))*np.cos(8*np.pi*(yy-center_2[1]))\n",
    "# u0 = u0_1 + u0_2\n",
    "u0 = np.exp(-250.0*(0.2*(xx-center[0])**2 + (yy-center[1])**2))*np.cos(8*np.pi*(yy-center[1]))\n",
    "ut0 = np.zeros([np.size(xx,axis=1),np.size(yy,axis=0)])\n",
    "vel = 1. + 0.0*yy - 0.5*(np.abs(yy+xx-0.)>0.4) + 0.*(np.abs(xx-0.4)<0.2)*(np.abs(yy-0.5)<0.1) #np.ones([np.size(xx,axis=1),np.size(yy,axis=0)]) #fig9 vel\n",
    "\n",
    "# def four_layers(x, y):\n",
    "#     res = x + np.pi / 3.1 * y\n",
    "#     if res < -1:\n",
    "#         return .2\n",
    "#     elif res < 0:\n",
    "#         return .6\n",
    "#     elif res < 1:\n",
    "#         return .8\n",
    "#     else:\n",
    "#         return 1\n",
    "#\n",
    "# # four layers velocity\n",
    "# dim = 128\n",
    "# v_x = np.linspace(-1, 1, num=dim)\n",
    "# v_y = np.linspace(-1, 1, num=dim)\n",
    "# z = np.array([four_layers(i, j) for j in v_y for i in v_x])\n",
    "# Z = np.array(z).reshape(dim, dim)\n",
    "# vel = Z\n",
    "\n",
    "veltest = (\n",
    "    #('waveguide',3. - 0.3*np.cos(np.pi*xx)),\\\n",
    "   #('inclusion',3.-0.5*(np.abs(xx-0.4)<0.2)*(np.abs(yy-0.5)<0.1)+0.5*(np.abs(xx-0.2)<0.2)*(np.abs(yy-0.3)<0.1) + 0.1*yy),\\\n",
    "   #('bp',gaussian_filter(resize(databp['V'][:,1300:3211],[128,128]),sigma=0)/1000),\\\n",
    "   #('marmousi',gaussian_filter(resize(datamarm['marm1smal'],[128,128]),sigma=0)/4),\\\n",
    "   ('refrac',vel),\n",
    "    #('four layers', vel),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 1)\n",
      "(64, 64, 1)\n",
      "(64, 64, 1)\n",
      "(64, 64, 1)\n",
      "(64, 64, 1)\n",
      "(64, 64, 1)\n",
      "(64, 64, 1)\n",
      "(64, 64, 1)\n",
      "(64, 64, 1)\n",
      "(64, 64, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-7ce785a77dc6>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     44\u001B[0m                              resize(vel,[ny,nx],order=4),dx*m,dt*rt,cT)\n\u001B[1;32m     45\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 46\u001B[0;31m         \u001B[0munn2\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mutnn2\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mwp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mApplyJNet2WaveSol\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0muc\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mutc\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mvel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdx\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mtir_model\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mm\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Documents/studies/master/master_thesis/code/generate_data/WavePostprocess.py\u001B[0m in \u001B[0;36mApplyJNet2WaveSol\u001B[0;34m(w, wt, c, dx, net, m)\u001B[0m\n\u001B[1;32m     30\u001B[0m     \u001B[0minputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstack\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwx\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mwy\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mwtc\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mctensor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 32\u001B[0;31m     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnet\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     33\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m     \u001B[0mvx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecord_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"DataParallel.forward\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice_ids\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 150\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodule\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    151\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mchain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuffers\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/studies/master/master_thesis/code/models/tiramisu.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     84\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mi\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mup_blocks\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     85\u001B[0m                 \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrescale\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 86\u001B[0;31m             \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdenseBlocksUp\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     87\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     88\u001B[0m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfinalConv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/studies/master/master_thesis/code/models/tiramisu.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    124\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    125\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mlayer\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 126\u001B[0;31m                 \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    127\u001B[0m                 \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# 1 = channel axis\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    128\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/studies/master/master_thesis/code/models/tiramisu.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    100\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    101\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 102\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    103\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    104\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/container.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    139\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    140\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 141\u001B[0;31m             \u001B[0minput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    142\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    444\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    445\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 446\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    447\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    448\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mConv3d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_ConvNd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    441\u001B[0m                             _pair(0), self.dilation, self.groups)\n\u001B[1;32m    442\u001B[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001B[0;32m--> 443\u001B[0;31m                         self.padding, self.dilation, self.groups)\n\u001B[0m\u001B[1;32m    444\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    445\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for velname, vel in veltest:\n",
    "\n",
    "    #### Fine solution ####\n",
    "    uf = np.zeros([xx.shape[0],xx.shape[1],mt])\n",
    "    utf = np.zeros([xx.shape[0],xx.shape[1],mt])\n",
    "    uf[:,:,0] = u0\n",
    "    utf[:,:,0] = ut0\n",
    "    for j in range(1,mt):\n",
    "        uf[:,:,j],utf[:,:,j] = wave2.velocity_verlet_time_integrator(uf[:,:,j-1],utf[:,:,j-1],vel,dx,dt,cT)\n",
    "\n",
    "    #### Coarse solution ####\n",
    "    ucc = np.zeros([xx.shape[0],xx.shape[1],mt])\n",
    "    utcc = np.zeros([xx.shape[0],xx.shape[1],mt])\n",
    "    ucc[:,:,0] = u0\n",
    "    utcc[:,:,0] = ut0\n",
    "    uc = resize(ucc[:,:,0],[ny,nx],order=4)\n",
    "    utc = resize(utcc[:,:,0],[ny,nx],order=4)\n",
    "    velc = resize(vel,[ny,nx],order=4)\n",
    "    \n",
    "    for j in range(1,mt):\n",
    "        uc, utc = wave2.velocity_verlet_time_integrator(uc,utc,velc,dx*m,dt*rt,cT)\n",
    "        ucc[:,:,j] = resize(uc,[xx.shape[0],xx.shape[1]],order=4)\n",
    "        utcc[:,:,j] = resize(utc,[xx.shape[0],xx.shape[1]],order=4)\n",
    "\n",
    "    #### UNet solution ####\n",
    "    unn1 = np.zeros([xx.shape[0],xx.shape[1],mt])\n",
    "    utnn1 = np.zeros([xx.shape[0],xx.shape[1],mt])\n",
    "    unn1[:,:,0] = u0\n",
    "    utnn1[:,:,0] = ut0\n",
    "    for j in range(1,mt):\n",
    "        uc,utc = wave2.velocity_verlet_time_integrator(resize(unn1[:,:,j-1],[ny,nx],order=4),\n",
    "                             resize(utnn1[:,:,j-1],[ny,nx],order=4),\n",
    "                             resize(vel,[ny,nx],order=4),dx*m,dt*rt,cT)\n",
    "        unn1[:,:,j],utnn1[:,:,j] = wp.ApplyJNet2WaveSol(uc,utc,vel,dx,unet_model,m)\n",
    "\n",
    "    #### Tiramisu solution ####\n",
    "    unn2 = np.zeros([xx.shape[0],xx.shape[1],mt])\n",
    "    utnn2 = np.zeros([xx.shape[0],xx.shape[1],mt])\n",
    "    unn2[:,:,0] = u0\n",
    "    utnn2[:,:,0] = ut0\n",
    "    for j in range(1,mt):\n",
    "        uc,utc = wave2.velocity_verlet_time_integrator(resize(unn2[:,:,j-1],[ny,nx],order=4),\n",
    "                             resize(utnn2[:,:,j-1],[ny,nx],order=4),\n",
    "                             resize(vel,[ny,nx],order=4),dx*m,dt*rt,cT)\n",
    "\n",
    "        unn2[:,:,j],utnn2[:,:,j] = wp.ApplyJNet2WaveSol(uc,utc,vel,dx,tir_model,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tj = 4\n",
    "fig1 = plt.figure(figsize=(16,19))\n",
    "\n",
    "ax1 = fig1.add_subplot(3,2,1)\n",
    "pos1 = ax1.imshow(vel,extent=(-1,1,-1,1))\n",
    "ax1.set_title('velocity', fontsize=20)\n",
    "plt.xticks([-1,1])\n",
    "plt.yticks([-1,1])\n",
    "plt.colorbar(pos1)\n",
    "\n",
    "ax2 = fig1.add_subplot(3,2,2)\n",
    "pos2 = ax2.imshow(u0,extent=(-1,1,-1,1))\n",
    "ax2.set_title('init. condition', fontsize=20)\n",
    "plt.xticks([-1,1])\n",
    "plt.yticks([-1,1])\n",
    "plt.colorbar(pos2)\n",
    "\n",
    "ax3 = fig1.add_subplot(3,2,3)\n",
    "pos3 = ax3.imshow(WaveUtil.WaveEnergyField(uf[:,:,tj],utf[:,:,tj],vel,dx)*dx*dx,vmax=0.005,extent=(-1,1,-1,1))\n",
    "ax3.set_title('fine', fontsize=20)\n",
    "plt.xticks([-1,1])\n",
    "plt.yticks([-1,1])\n",
    "plt.plot([-0.5,0.4],[0.45,0.85],'r',linewidth=4)\n",
    "plt.plot([0.,0.],[0.,0.4],'w',linewidth=4)\n",
    "plt.plot([0.,-0.2],[0.4,0.84],'w',linewidth=4)\n",
    "plt.colorbar(pos1,ticks = [0,0.002,0.005])\n",
    "\n",
    "ax4 = fig1.add_subplot(3,2,4)\n",
    "pos4 = ax4.imshow(WaveUtil.WaveEnergyField(ucc[:,:,tj],utcc[:,:,tj],vel,dx)*dx*dx,vmax=.005,extent=(-1,1,-1,1))\n",
    "ax4.set_title('coarse', fontsize=20)\n",
    "plt.xticks([-1,1])\n",
    "plt.yticks([-1,1])\n",
    "plt.plot([-0.5,0.4],[0.45,0.85],'r',linewidth=4)\n",
    "plt.plot([0.,0.],[0.,0.4],'w',linewidth=4)\n",
    "plt.plot([0.,-0.2],[0.4,0.84],'w',linewidth=4)\n",
    "plt.colorbar(pos4,ticks = [0,0.002,0.005])\n",
    "\n",
    "ax5 = fig1.add_subplot(3,2,5)\n",
    "pos5 = ax5.imshow(WaveUtil.WaveEnergyField(unn1[:,:,tj],utnn1[:,:,tj],vel,dx)*dx*dx,vmax=.005,extent=(-1,1,-1,1))\n",
    "ax5.set_title(r'unet 6lvl $\\Delta t^*=0.2 256^2$', fontsize=20)\n",
    "plt.xticks([-1,1])\n",
    "plt.yticks([-1,1])\n",
    "plt.plot([-0.5,0.4],[0.45,0.85],'r',linewidth=4)\n",
    "plt.plot([0.,0.],[0.,0.4],'w',linewidth=4)\n",
    "plt.plot([0.,-0.2],[0.4,0.84],'w',linewidth=4)\n",
    "plt.colorbar(pos5,ticks = [0,0.002,0.005])\n",
    "\n",
    "ax6 = fig1.add_subplot(3,2,6)\n",
    "pos6 = ax6.imshow(WaveUtil.WaveEnergyField(unn2[:,:,tj],utnn2[:,:,tj],vel,dx)*dx*dx,vmax=0.005,extent=(-1,1,-1,1))\n",
    "ax6.set_title(r'tiramisu $\\Delta t^*=0.2$ 256^2', fontsize=20)\n",
    "plt.xticks([-1,1])\n",
    "plt.yticks([-1,1])\n",
    "plt.plot([-0.5,0.4],[0.45,0.85],'r',linewidth=4)\n",
    "plt.plot([0.,0.],[0.,0.4],'w',linewidth=4)\n",
    "plt.plot([0.,-0.2],[0.4,0.84],'w',linewidth=4)\n",
    "plt.colorbar(pos6, ticks = [0,0.002,0.005])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0 0.0\n",
      "1 2.222971015433661e-07 8.832149092691034e-08\n",
      "2 3.5725409319420366e-07 1.933508016532087e-07\n",
      "3 3.45963532253423e-07 2.7905050801818685e-07\n",
      "4 4.0802250862262545e-07 3.63439314263032e-07\n",
      "5 4.1783613977965456e-07 3.973962301699262e-07\n",
      "6 3.9512275344292934e-07 3.887815867524507e-07\n",
      "7 3.65186823515949e-07 3.6404253018210757e-07\n"
     ]
    }
   ],
   "source": [
    "# compare wave energy norm errors:\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for it in range(8):\n",
    "    wf = WaveUtil.WaveEnergyField(uf[:,:,it], utf[:,:,it], vel, dx)*dx*dx\n",
    "    w1 = WaveUtil.WaveEnergyField(unn1[:,:,it], utnn1[:,:,it], vel, dx)*dx*dx\n",
    "    w2 = WaveUtil.WaveEnergyField(unn2[:,:,it], utnn2[:,:,it], vel, dx)*dx*dx\n",
    "\n",
    "    mse1 = mean_squared_error(wf, w1)\n",
    "    mse2 = mean_squared_error(wf, w2)\n",
    "\n",
    "    print(it, mse1, mse2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\ntiramisu128_10 outperforms unet128_9a with way less tuning parameters\\ntraining unet_128_9a and unet_128_9b is stable, and gives very similar results\\n\\ntiramisu256_1 outperforms unet256_10 with way less tuning parameters, but similar training time (3x as much parameters)\\n'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "tiramisu128_10 outperforms unet128_9a with way less tuning parameters\n",
    "training unet_128_9a and unet_128_9b is stable, and gives very similar results\n",
    "\n",
    "tiramisu256_1 outperforms unet256_10 with way less tuning parameters, but similar training time (3x as much parameters)\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
